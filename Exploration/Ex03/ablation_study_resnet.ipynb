{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haji8-de/AIFFEL_quest_rs/blob/main/Exploration/Ex03/ablation_study_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHmJbXBks8pG"
      },
      "source": [
        "# 기본 초기화 소스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU4ol_fiKTOD",
        "outputId": "63f2c5c6-9794-4560-cca3-1ba3700b6a70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2hyrckZzxIQD"
      },
      "outputs": [],
      "source": [
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchinfo import summary\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AeE3xIbtJMMM"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    return np.transpose(npimg, (1, 2, 0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sQskIfX-yMVu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "MyOFxhzqKTOV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "\n",
        "hyperparams = {\n",
        "    \"batch_size\": 4,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"epochs\": 5,\n",
        "    \"transform\": transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.48235, 0.45882, 0.40784],\n",
        "                std=[0.229, 0.224, 0.225],\n",
        "            ),\n",
        "        ]\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h16SxMH4tGaz"
      },
      "source": [
        "## 데이터 로드 소스 from torchVision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KrWgUf69OM9E"
      },
      "outputs": [],
      "source": [
        "trainset = torchvision.datasets.Imagenette(root='./data', split='train', download=True, transform=hyperparams['transform'])\n",
        "testset = torchvision.datasets.Imagenette(root='./data', split='val', download=True, transform=hyperparams['transform'])\n",
        "\n",
        "trainloader_2 = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "testloader_2 = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
        "\n",
        "# trainloader_2 = torch.utils.data.DataLoader(ds_split['train'], batch_size=32, shuffle=True)\n",
        "# testloader_2 = torch.utils.data.DataLoader(ds_split['test'], batch_size=32, shuffle=False)\n",
        "# validationloader_2 = torch.utils.data.DataLoader(ds_split['validation'], batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MVCTX7gOsjt8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qeb3sP1ktMw8"
      },
      "source": [
        "## 이진 분류된 이미지의 결과를 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "67d5ed55"
      },
      "outputs": [],
      "source": [
        "# def show_multiple_images_binary_label(dataset, n_images=9):\n",
        "#     dataiter = iter(dataset)\n",
        "#     images, labels = next(dataiter)\n",
        "#     fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
        "#     axes = axes.flatten()\n",
        "\n",
        "#     # OxfordIIITPet 데이터셋의 이진 레이블에 대한 이름을 정의합니다.\n",
        "#     # 'binary-category'는 일반적으로 0:cat, 1:dog을 나타냅니다.\n",
        "#     binary_labels_map = ['cat', 'dog']\n",
        "\n",
        "#     for i in range(n_images):\n",
        "#         ax = axes[i]\n",
        "#         img = imshow(images[i])\n",
        "#         ax.imshow(img)\n",
        "\n",
        "#         # labels는 (binary_labels_batch_tensor, category_labels_batch_tensor) 형태이므로\n",
        "#         # 첫 번째 텐서(binary_labels_batch_tensor)에서 i번째 항목을 가져옵니다.\n",
        "#         binary_label_idx = labels[0][i].item()\n",
        "\n",
        "#         # 인덱스가 유효한 범위 내에 있는지 확인하고, 아니면 'Unknown'으로 처리합니다.\n",
        "#         if 0 <= binary_label_idx < len(binary_labels_map):\n",
        "#             label_text = binary_labels_map[binary_label_idx]\n",
        "#         else:\n",
        "#             label_text = f\"Unknown (Index: {binary_label_idx})\"\n",
        "\n",
        "#         ax.set_title(f\"Label: {label_text}\")\n",
        "#         ax.axis('off')\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "b9ff5395"
      },
      "outputs": [],
      "source": [
        "# # trainloader_2 에 대한 이진 레이블 시각화\n",
        "# print(\"Trainloader_2 (Binary Labels):\")\n",
        "# show_multiple_images_binary_label(trainloader_2)\n",
        "\n",
        "# # testloader_2 에 대한 이진 레이블 시각화\n",
        "# print(\"\\nTestloader_2 (Binary Labels):\")\n",
        "# show_multiple_images_binary_label(testloader_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPLRP_iZxTO9"
      },
      "source": [
        "# ResNet 구현체"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BasicBlock"
      ],
      "metadata": {
        "id": "91aCUMrMFNAt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dynO2yoHKGZd"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            inplanes, planes,\n",
        "            kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes,\n",
        "            kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or inplanes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    inplanes, self.expansion*planes,\n",
        "                    kernel_size=1, stride=stride, bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V2Ikz1M1FRmx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## resnet 구현체"
      ],
      "metadata": {
        "id": "PoSxKL9iFVJN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ocWtDQzAKI7Y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(self.inplanes),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "        self.stage1 = self._make_layer(block, 64, layers[0], stride=1)\n",
        "        self.stage2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.stage3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.stage4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(num_blocks - 1):\n",
        "            layers.append(block(self.inplanes, planes, 1))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stem(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다양한 resnet 생성"
      ],
      "metadata": {
        "id": "ggX8eqqGFhJW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwI1e8N2KTOc",
        "outputId": "c34dd0f7-0d60-494a-ef62-2893312c85a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21289802\n",
            "21797672\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "from torchinfo import summary\n",
        "\n",
        "resnet34 = ResNet(BasicBlock, [3, 4, 6, 3], 10)\n",
        "torch_model = models.resnet34(weights=\"ResNet34_Weights.IMAGENET1K_V1\")\n",
        "\n",
        "resnet34_info = summary(resnet34, (1, 3, 224, 224), verbose=0)\n",
        "torch_model_info = summary(torch_model, (1, 3, 224, 224), verbose=0)\n",
        "\n",
        "print(resnet34_info.total_params)\n",
        "print(torch_model_info.total_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## display_predictions_binary_label\n",
        "예측된 라벨의 정확도 확인을 위해\n",
        "예측라벨과 정답 라벨을 이미지와 함께 노출\n",
        "\n",
        "* class_names = ['cat', 'dog']"
      ],
      "metadata": {
        "id": "TO2b18mnGRFY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "V7g9uNPp9qkJ"
      },
      "outputs": [],
      "source": [
        "# def show_multiple_images_binary_label(dataset, n_images=9):\n",
        "#     dataiter = iter(dataset)\n",
        "#     images, labels = next(dataiter)\n",
        "#     fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
        "#     axes = axes.flatten()\n",
        "\n",
        "#     # OxfordIIITPet 데이터셋의 이진 레이블에 대한 이름을 정의합니다.\n",
        "\n",
        "#     for i in range(n_images):\n",
        "#         ax = axes[i]\n",
        "#         img = imshow(images[i])\n",
        "#         ax.imshow(img)\n",
        "\n",
        "#         # labels는 (binary_labels_batch_tensor, category_labels_batch_tensor) 형태이므로\n",
        "#         # 첫 번째 텐서(binary_labels_batch_tensor)에서 i번째 항목을 가져옵니다.\n",
        "\n",
        "#         binary_label_idx = labels[0][i].item()\n",
        "\n",
        "#         # 인덱스가 유효한 범위 내에 있는지 확인하고, 아니면 'Unknown'으로 처리합니다.\n",
        "#         if 0 <= binary_label_idx < len(binary_labels_map):\n",
        "#             label_text = binary_labels_map[binary_label_idx]\n",
        "#         else:\n",
        "#             label_text = f\"Unknown (Index: {binary_label_idx})\"\n",
        "\n",
        "#         ax.set_title(f\"Label: {label_text}\")\n",
        "#         ax.axis('off')\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "# # 'binary-category'는 일반적으로 0:cat, 1:dog을 나타냅니다.\n",
        "# binary_labels_map = ['cat', 'dog']\n",
        "# def display_predictions_binary_label(loader, model, class_names, device, n_images=9):\n",
        "#     dataiter = iter(loader)\n",
        "#     images, labels = next(dataiter) # Get a batch of images and labels\n",
        "\n",
        "#     fig, axes = plt.subplots(3, 3, figsize=(8, 8)) # Create a 3x3 grid for images\n",
        "#     axes = axes.flatten() # Flatten the 2D array of axes for easier iteration\n",
        "\n",
        "#     with torch.no_grad(): # Disable gradient calculation for inference\n",
        "#         for i in range(n_images):\n",
        "#             if i >= len(images): # Ensure we don't go out of bounds if batch size is smaller than n_images\n",
        "#                 break\n",
        "\n",
        "#             ax = axes[i]\n",
        "#             img = imshow(images[i]) # Use the helper function to properly display the image\n",
        "#             ax.imshow(img)\n",
        "\n",
        "#             # Get model output for the image\n",
        "#             outputs = model(images[i].unsqueeze(0).to(device)) # Add batch dimension and move to device\n",
        "\n",
        "#             # Get predicted class\n",
        "#             _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "#             # Get the class names\n",
        "#             predicted_class_name = class_names[predicted[0]]\n",
        "#             # print(predicted_class_name)\n",
        "\n",
        "#             binary_label_idx = labels[0][i].item()\n",
        "#             # true_class_name = class_names[labels[i]]\n",
        "\n",
        "#             # Set the title with true and predicted labels\n",
        "#             # 인덱스가 유효한 범위 내에 있는지 확인하고, 아니면 'Unknown'으로 처리합니다.\n",
        "#             if 0 <= binary_label_idx < len(binary_labels_map):\n",
        "#                 label_text = binary_labels_map[binary_label_idx]\n",
        "#             else:\n",
        "#                 label_text = f\"Unknown (Index: {binary_label_idx})\"\n",
        "\n",
        "#             ax.set_title(f\"True: {label_text}, Label: {predicted_class_name}\")\n",
        "#             # ax.set_title(f\"True: {true_class_name}\\nPred: {predicted_class_name}\", fontsize=10)\n",
        "#             ax.axis('off') # Hide axes ticks\n",
        "\n",
        "#     plt.tight_layout() # Adjust subplot parameters for a tight layout\n",
        "#     plt.show() # Display the plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "oA8q22cJkSTe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "9KVnLfg0kSTg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OmcMzgB02zb"
      },
      "source": [
        "# ResNet-34, ResNet-50 각각 plain모델과 residual모델"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PlainBlock 선언"
      ],
      "metadata": {
        "id": "oPopdN_pGpZA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Cy-bjOzo01m3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PlainBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet의 BasicBlock과 구조는 같지만,\n",
        "    Skip Connection(+ identity)이 없는 블록\n",
        "    \"\"\"\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(PlainBlock, self).__init__()\n",
        "\n",
        "        # 첫 번째 Conv (Stride가 1이 아닐 수도 있음)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # 두 번째 Conv\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Convolution 통과\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        # [차이점] 여기서 ResNet은 'out += x'를 하지만, Plain 모델은 하지 않습니다.\n",
        "\n",
        "        out = self.relu(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bulid Plainnet 선언"
      ],
      "metadata": {
        "id": "k-qSo8J-GvoA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wyvfHH8x0HkM"
      },
      "outputs": [],
      "source": [
        "def build_plainnet(is_50=False, input_shape=(32, 32, 3), num_classes=10):\n",
        "    \"\"\"\n",
        "    ResNet-34와 동일한 층 수를 가지지만,\n",
        "    Skip Connection이 없는 PlainNet-34 모델을 생성합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    # ResNet-34와 동일한 레이어 구성\n",
        "    layers = [3, 4, 6, 3]\n",
        "\n",
        "    # 블록 타입으로 BasicBlock 대신 PlainBlock을 사용\n",
        "    # is_50(Bottleneck) 옵션은 PlainNet 실험에서 보통 34층 이하를 비교하므로 무시하거나 False로 둠\n",
        "    model = ResNet(PlainBlock, layers, num_classes=num_classes)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plainnet_34_2 수행"
      ],
      "metadata": {
        "id": "jeb-EOORG3Hp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "v2JFSlQ0KTOn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "plainnet_34_2 = build_plainnet(is_50=False, input_shape=(32, 32,3), num_classes=10)\n",
        "# print(summary(plainnet_34_2))\n",
        "\n",
        "# print(plainnet_34_2.total_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plainnet_50_2"
      ],
      "metadata": {
        "id": "vjW6vWf4G_qK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습부"
      ],
      "metadata": {
        "id": "5TgRfmBrHHSg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "X2Xco9d8kSTo"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 256\n",
        "EPOCH = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rMPXRVzVkSTr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "MeDUCnml2EGH"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def model_run_epoch_classnet(origin_model):\n",
        "    # 1. Setup\n",
        "    current_time = time.time()\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Move model to device FIRST\n",
        "    model = origin_model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    # CRITICAL FIX 1: Define optimizer AFTER moving model to device,\n",
        "    # and use 'model.parameters()', NOT 'origin_model.parameters()'.\n",
        "    # If you optimize origin_model (CPU), the GPU model won't update!\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "    origin_model_train_losses = []\n",
        "    origin_model_val_accuracy = []\n",
        "\n",
        "    print(f\"Training on device: {device}\")\n",
        "\n",
        "    for epoch in range(EPOCH):\n",
        "        # CRITICAL FIX 2: Use 'model.train()', not the global variable 'resnet34'\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        epoch_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(trainloader_2, 0):\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            # --- [FIX FOR VALUE ERROR] ---\n",
        "            # Check if labels is a list (multi-label) or just a Tensor (standard)\n",
        "            if isinstance(labels, list):\n",
        "                targets = labels[0].to(device).long()\n",
        "            else:\n",
        "                # If labels is already the tensor, use it directly\n",
        "                targets = labels.to(device).long()\n",
        "            # -----------------------------\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Safety check (Optional but helpful for debugging)\n",
        "            if targets.shape[0] != outputs.shape[0]:\n",
        "                 print(f\"Error: Shape Mismatch! Output: {outputs.shape}, Target: {targets.shape}\")\n",
        "                 break\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Stats\n",
        "            loss_val = loss.item()\n",
        "            running_loss += loss_val\n",
        "            epoch_loss += loss_val\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "            if i % 100 == 99:\n",
        "                print(f\"[{epoch + 1}, {i + 1:5d}] Step Loss: {running_loss / 100:.3f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # ... (rest of your epoch calculation code) ...\n",
        "        avg_train_loss = epoch_loss / len(trainloader_2)\n",
        "        train_acc = 100 * correct / total\n",
        "        origin_model_train_losses.append(avg_train_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} Finished. Avg Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "\n",
        "        # ... (Validation loop should apply the same fix for 'targets') ..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# model = resnet34.to(device)\n",
        "# criterion = nn.CrossEntropyLoss().to(device)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=hyperparams[\"learning_rate\"])"
      ],
      "metadata": {
        "id": "tDnjlVDqvtU8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 트레이닝"
      ],
      "metadata": {
        "id": "2GNBo-u4Hfgr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdb30TxX2HsG",
        "outputId": "4c9ee0cd-ba3a-4b6d-c7e1-6220e5eb1c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on device: cuda\n",
            "[1,   100] Step Loss: 2.022\n",
            "[1,   200] Step Loss: 1.677\n"
          ]
        }
      ],
      "source": [
        "l34,a34 = model_run_epoch_classnet(resnet34)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo48nQmOFDwE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def figure_2chart(title, l1,a1,l2,a2):\n",
        "\n",
        "    # --- 데이터 준비 (예시 변수명입니다. 실제 저장한 변수명으로 교체하세요) ---\n",
        "    # 예: epochs = range(1, 11)\n",
        "    epochs = range(1, len(a1) + 1)\n",
        "\n",
        "    # 1. 그래프 크기 설정\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # [왼쪽 그래프] Validation Accuracy 비교\n",
        "    # -------------------------------------------------------\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, a1, 'b-o', label='Res'+title+' (Shortcut O)')\n",
        "    plt.plot(epochs, a2, 'r--s', label='Plain'+title+' (Shortcut X)')\n",
        "\n",
        "    plt.title('Validation Accuracy Comparison', fontsize=15)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.legend(fontsize=12)\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # [오른쪽 그래프] Validation Loss 비교\n",
        "    # (Loss 리스트가 있다면 이 부분을 주석 해제하고 사용하세요)\n",
        "    # -------------------------------------------------------\n",
        "    plt.subplot(1, 2, 2)\n",
        "\n",
        "    plt.plot(epochs, l1, 'b-o', label='Res'+title+' Loss')\n",
        "    plt.plot(epochs, l2, 'r--s', label='Plain'+title+' Loss')\n",
        "    plt.title('Validation Loss Comparison', fontsize=15)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.legend(fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OTFjiU42Jza"
      },
      "outputs": [],
      "source": [
        "lp34,ap34 = model_run_epoch_classnet(plainnet_34_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofcztwylFDwK"
      },
      "outputs": [],
      "source": [
        "figure_2chart(\"net34\", l34,a34,lp34,ap34)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZxzAJp1Ht9P2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imU18BpokSTf",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# class_names = binary_labels_map\n",
        "# display_predictions_binary_label(trainloader_2, resnet_34_2, class_names, device, n_images=9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c4NeaXZiIjRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTiwTYZdFDwQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}